{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIx-nje0Z3L1"
      },
      "outputs": [],
      "source": [
        "!pip install trl\n",
        "!pip intall transformers\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG9PdTeaarTX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from trl import RewardTrainer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1dA5yyEwuDg"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"CarperAI/openai_summarize_comparisons\"\n",
        "prepared_dataset = ... # load a subset of dataset\n",
        "prepared_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8aYRFH2Rw2QY"
      },
      "outputs": [],
      "source": [
        "model_name = ... # load distil roberta base model\n",
        "\n",
        "model = ... # load pre-trained model\n",
        "tokenizer = ... # load the corresponding tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "def formatting_func(examples):\n",
        "    kwargs = {\"padding\": \"max_length\", \"truncation\": True, \"max_length\": 512, \"return_tensors\": \"pt\"}\n",
        "\n",
        "    # Prepend the prompt and a line break to the original_response and response-1 fields.\n",
        "    prompt_plus_chosen_response = ... # chosen prompts\n",
        "    prompt_plus_rejected_response = ... # rejected prompts\n",
        "\n",
        "    # Then tokenize these modified fields.\n",
        "    tokens_chosen = ... # encode the chosen prompts\n",
        "    tokens_rejected = ... # encode the rejected prompts\n",
        "\n",
        "    return {\n",
        "        \"input_ids_chosen\": tokens_chosen[\"input_ids\"][0], \"attention_mask_chosen\": tokens_chosen[\"attention_mask\"][0],\n",
        "        \"input_ids_rejected\": tokens_rejected[\"input_ids\"][0], \"attention_mask_rejected\": tokens_rejected[\"attention_mask\"][0]\n",
        "    }\n",
        "\n",
        "formatted_dataset = prepared_dataset.map(formatting_func)\n",
        "formatted_dataset = formatted_dataset.train_test_split()\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/rm\",\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    logging_steps=500\n",
        ")\n",
        "\n",
        "trainer = ... # reawrd trainer initialization\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Sr0qGgKbx6Zy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}